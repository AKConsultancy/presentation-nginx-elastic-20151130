# http://nginx.com/resources/admin-guide/caching/
# all this lives inside a http{} block

proxy_cache_path /data/nginx/cache/es  keys_zone=es_cache:10m  max_size=1g;

upstream es {
    server 127.0.0.1:9200;
}

server {
    listen 0.0.0.0:8081; # change to bind to specific nic
    location / {
        proxy_pass http://es; # uri will be passed unchanged
        proxy_cache es_cache;
        proxy_cache_valid 200 302 12h;
        proxy_cache_key "$request_uri$request_body";
        # allow only 1 concurrent request per cache key
        proxy_cache_lock on;
        # when client aborts, do not close the conn to upstream 
        # want to read that data and cache it! 
        proxy_ignore_client_abort on;
        # apply backpressure on heavy load
        proxy_connect_timeout 1s;
        proxy_send_timeout 1s;
        proxy_read_timeout 5s;
        # allow to use stale cache on error conditions
        proxy_cache_use_stale updating error timeout;
        # allow to bypass cache when 'Cache-Control: bypass' header present
        proxy_cache_bypass $http_cache_control;
        # return cache status as response header; for metrics
        add_header X-Proxy-Cache $upstream_cache_status;
    }
}

